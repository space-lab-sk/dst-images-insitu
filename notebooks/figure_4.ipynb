{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4 reproduction\n",
    "\n",
    "In this notebook, we are reproducing figure 4, GRU-Attn-IEC deep learning approach we used in paper.  \n",
    "It will be just \"forward pass\" of this model so you can play around and print shapes and see how it goes under the hood.\n",
    "\n",
    "<img src=\"paper_figures/gru-attn-iec.png\" alt=\"Figure 4\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "ie_input_size = 9 # euv visual features and in situ input\n",
    "c_input_size = 4 # coronagraph visual features\n",
    "hidden_size = 64\n",
    "hidden_size2 = 64\n",
    "output_size = 1\n",
    "num_gru_layers = 2\n",
    "num_heads = 4\n",
    "\n",
    "# random tensors -> inputs\n",
    "x = torch.randn(32, 100, 9)\n",
    "x_q = torch.randn(32, 100, 4)\n",
    "\n",
    "# torch layers\n",
    "gru1 = nn.GRU(ie_input_size, hidden_size, num_gru_layers, batch_first=True)\n",
    "\n",
    "gru2 = nn.GRU(16, hidden_size2, num_gru_layers, batch_first=True)\n",
    "linear1 = nn.Linear(c_input_size, 16)\n",
    "gelu = nn.GELU()\n",
    "mha = nn.MultiheadAttention(embed_dim=hidden_size2, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "fc_out = nn.Linear(hidden_size + hidden_size2, output_size)\n",
    "\n",
    "# forward pass\n",
    "h0 = torch.zeros(num_gru_layers, x.size(0), hidden_size)\n",
    "out1, _ = gru1(x, h0)\n",
    "\n",
    "x_q = gelu(linear1(x_q))\n",
    "h02 = torch.zeros(num_gru_layers, x_q.size(0), hidden_size2)\n",
    "out2, _ = gru2(x_q, h02)\n",
    "\n",
    "context, _ = mha(out2[:, -1:, :], out2, out2)\n",
    "context = context.squeeze(1)\n",
    "\n",
    "concated = torch.cat((out1[:, -1, :], context), 1)\n",
    "out = fc_out(concated)\n",
    "\n",
    "print(f\"output: {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
